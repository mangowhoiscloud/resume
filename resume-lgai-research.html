<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>류지환 Resume - AI Agent Engineer</title>
<style>
    @page {
        size: A4;
        margin: 15mm;
    }

    * {
        box-sizing: border-box;
    }

    body {
        font-family: 'Apple SD Gothic Neo', 'Malgun Gothic', -apple-system, BlinkMacSystemFont, sans-serif;
        line-height: 1.6;
        font-size: 9.5pt;
        color: #2c3e50;
        max-width: 210mm;
        margin: 0 auto;
        padding: 20px;
        background: #fff;
    }

    /* Language Toggle */
    .lang-toggle {
        position: fixed;
        top: 20px;
        right: 20px;
        display: flex;
        gap: 5px;
        background: #fff;
        padding: 5px;
        border-radius: 8px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        z-index: 1000;
    }

    .lang-toggle button {
        padding: 8px 16px;
        border: none;
        border-radius: 6px;
        cursor: pointer;
        font-size: 12px;
        font-weight: 600;
        transition: all 0.2s ease;
        background: #f0f0f0;
        color: #666;
    }

    .lang-toggle button.active {
        background: #3498db;
        color: #fff;
    }

    .lang-toggle button:hover:not(.active) {
        background: #e0e0e0;
    }

    /* Language visibility */
    .lang-ko, .lang-en { display: none; }
    body.ko .lang-ko { display: inline; }
    body.en .lang-en { display: inline; }
    body.ko .lang-ko-block { display: block; }
    body.en .lang-en-block { display: block; }
    body.ko .lang-en-block { display: none; }
    body.en .lang-ko-block { display: none; }

    /* Header */
    .header {
        text-align: center;
        margin-bottom: 20px;
        padding-bottom: 15px;
        border-bottom: 3px solid #3498db;
    }

    .header h1 {
        font-size: 22pt;
        margin: 0 0 5px 0;
        color: #2c3e50;
        font-weight: 700;
    }

    .header .subtitle {
        font-size: 12pt;
        color: #7f8c8d;
        margin: 0;
    }

    /* Contact Info */
    .contact-info {
        display: flex;
        justify-content: center;
        flex-wrap: wrap;
        gap: 15px;
        margin-top: 10px;
        font-size: 9pt;
    }

    .contact-info a {
        color: #3498db;
        text-decoration: none;
    }

    .contact-info span {
        color: #95a5a6;
    }

    /* About Section */
    .about-section {
        background: linear-gradient(90deg, #f8f9fa 0%, #fff 100%);
        border-left: 4px solid #3498db;
        padding: 15px 20px;
        margin: 15px 0;
        font-size: 9.5pt;
        line-height: 1.7;
        color: #34495e;
    }

    .about-section p {
        margin: 0;
    }

    .about-section strong {
        color: #2c3e50;
    }

    /* Section Headers */
    h2 {
        font-size: 13pt;
        color: #2c3e50;
        border-left: 4px solid #3498db;
        padding-left: 10px;
        margin-top: 25px;
        margin-bottom: 12px;
        page-break-after: avoid;
    }

    h3 {
        font-size: 11pt;
        color: #34495e;
        margin-top: 15px;
        margin-bottom: 8px;
        page-break-after: avoid;
    }

    /* Timeline Graph - Vertical Style */
    .timeline-section {
        margin: 25px 0;
        page-break-inside: avoid;
    }

    .timeline-section h2 {
        border-left: 4px solid #3498db;
        padding-left: 10px;
        margin-bottom: 20px;
    }

    .timeline-container {
        position: relative;
    }

    .timeline-item {
        position: relative;
        padding: 12px 0 12px 20px;
        border-left: none;
    }

    /* Timeline dot */
    .timeline-item::before {
        content: '';
        position: absolute;
        left: -27px;
        top: 16px;
        width: 14px;
        height: 14px;
        border-radius: 50%;
        border: 3px solid #fff;
        box-shadow: 0 0 0 2px currentColor, 0 2px 8px rgba(0,0,0,0.15);
    }

    .timeline-item.education::before { color: #3498db; background: #3498db; }
    .timeline-item.project::before { color: #27ae60; background: #27ae60; }
    .timeline-item.work::before { color: #e74c3c; background: #e74c3c; }
    .timeline-item.current::before {
        color: #9b59b6;
        background: #9b59b6;
        animation: pulse-dot 2s infinite;
    }

    @keyframes pulse-dot {
        0%, 100% { box-shadow: 0 0 0 2px #9b59b6, 0 2px 8px rgba(0,0,0,0.15); }
        50% { box-shadow: 0 0 0 4px #9b59b6, 0 2px 12px rgba(155,89,182,0.4); }
    }

    .timeline-item .item-period {
        font-size: 8pt;
        color: #7f8c8d;
        font-weight: 600;
        display: block;
        margin-bottom: 3px;
    }

    .timeline-item .item-title {
        font-size: 10pt;
        font-weight: 700;
        color: #2c3e50;
    }

    .timeline-item .item-desc {
        font-size: 8.5pt;
        color: #5d6d7e;
        margin-top: 2px;
    }

    .timeline-row {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 0 40px;
    }

    .timeline-row > div {
        position: relative;
        padding-left: 30px;
    }

    .timeline-row > div::before {
        content: '';
        position: absolute;
        left: 8px;
        top: 0;
        bottom: 0;
        width: 3px;
        background: linear-gradient(180deg, #3498db 0%, #9b59b6 100%);
        border-radius: 2px;
    }

    .timeline-legend {
        display: flex;
        justify-content: flex-start;
        gap: 20px;
        margin-top: 15px;
        padding-left: 30px;
        font-size: 8pt;
    }

    .legend-item {
        display: flex;
        align-items: center;
        gap: 5px;
    }

    .legend-color {
        width: 10px;
        height: 10px;
        border-radius: 50%;
    }

    .legend-color.education { background: #3498db; }
    .legend-color.project { background: #27ae60; }
    .legend-color.work { background: #e74c3c; }
    .legend-color.current { background: #9b59b6; }

    /* Experience & Projects */
    .experience-item, .project-item {
        margin-bottom: 18px;
        page-break-inside: avoid;
    }

    .item-header {
        display: flex;
        justify-content: space-between;
        align-items: baseline;
        margin-bottom: 5px;
    }

    .item-title {
        font-size: 11pt;
        font-weight: 700;
        color: #2c3e50;
    }

    .item-subtitle {
        font-size: 9pt;
        color: #7f8c8d;
    }

    .item-period {
        font-size: 9pt;
        color: #95a5a6;
        white-space: nowrap;
    }

    .item-description {
        font-size: 9pt;
        color: #5d6d7e;
        margin: 5px 0;
        font-style: italic;
    }

    /* Lists */
    ul {
        padding-left: 18px;
        margin: 8px 0;
    }

    li {
        margin-bottom: 4px;
        font-size: 9pt;
    }

    li strong {
        color: #2c3e50;
    }

    /* Metrics Highlight */
    .metrics {
        background: #f8f9fa;
        border-left: 3px solid #27ae60;
        padding: 10px 15px;
        margin: 10px 0;
        font-size: 9pt;
    }

    .metrics strong {
        color: #27ae60;
    }

    /* Two Column Layout */
    .two-column {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 20px;
    }

    /* Print Styles */
    @media print {
        .lang-toggle {
            display: none !important;
        }

        body {
            padding: 0;
            -webkit-print-color-adjust: exact !important;
            print-color-adjust: exact !important;
        }

        a {
            text-decoration: none;
            color: #2c3e50;
        }

        .timeline-section {
            background: #f8f9fa !important;
        }

        h2 + ul, h3 + ul {
            page-break-inside: avoid;
        }

        .experience-item, .project-item {
            page-break-inside: avoid;
        }
    }

    @media (max-width: 768px) {
        .lang-toggle {
            top: 10px;
            right: 10px;
        }

        .lang-toggle button {
            padding: 6px 12px;
            font-size: 11px;
        }
    }
</style>
</head>
<body class="ko">

<!-- Language Toggle -->
<div class="lang-toggle">
    <button id="btn-ko" class="active" onclick="setLang('ko')">한국어</button>
    <button id="btn-en" onclick="setLang('en')">English</button>
</div>

<!-- Header -->
<div class="header">
    <h1>
        <span class="lang-ko">류지환 (Jihwan Ryu)</span>
        <span class="lang-en">Jihwan Ryu (류지환)</span>
    </h1>
    <p class="subtitle">AI Agent Engineer</p>
    <div class="contact-info">
        <span>ryoo0504@gmail.com</span>
        <a href="https://github.com/mangowhoiscloud">GitHub</a> <a href="https://github.com/mng990" style="color:#95a5a6">(Legacy)</a>
        <a href="https://rooftopsnow.tistory.com">Blog</a>
        <a href="https://linkedin.com/in/jihwan-ryu-b6b04a202">LinkedIn</a>
    </div>
</div>

<!-- About Me -->
<div class="about-section">
    <p class="lang-ko-block">
        <strong>AI Agent 시스템 설계와 LLM 서비스 최적화</strong>에 집중하는 백엔드 엔지니어입니다.
        Rakuten 페타바이트급 분산 스토리지 서버 개발을 거쳐, 현재 24-Node Kubernetes 클러스터에서 LangGraph 기반 10종 서브에이전트 Multi-Agent 시스템을 설계·개발·운영 중입니다.
        9분류 Intent Classifier에서 다단계 Confidence Scoring(LLM 신뢰도, 키워드 맵 보정, Chain-of-Intent 문맥 반영)으로 분류 후 Send API 동적 병렬 라우팅으로 복합 질의를 병렬 처리하고, LLMClientPort 추상화로 Multi-LLM Fallback Chain을 구현했습니다.
        LLM API n-hop 파이프라인(10-20s/req)의 고레이턴시에 대응하기 위해 Event Bus Layer(O(n×m) → O(n) 연결 복잡도)를 설계 개발, VU 50→500(x10), RPM 60→367.9(x6.1) 확장을 달성했습니다.
    </p>
    <p class="lang-en-block">
        Backend engineer focused on <strong>AI Agent system design and LLM service optimization</strong>.
        After developing Rakuten's petabyte-scale distributed storage servers, I now design, develop, and operate LangGraph-based 10-type sub-agent Multi-Agent systems on a 24-Node Kubernetes cluster.
        After classification through multi-stage Confidence Scoring (LLM confidence, keyword map calibration, Chain-of-Intent context) in the 9-class Intent Classifier, implemented Send API dynamic parallel routing for parallel processing of compound queries, and Multi-LLM Fallback Chain via LLMClientPort abstraction.
        To address LLM API n-hop pipeline latency (10-20s/req), designed Event Bus Layer (O(n×m) → O(n) connection complexity), achieving VU 50→500(x10), RPM 60→367.9(x6.1) scaling.
    </p>
</div>

<!-- Timeline Section -->
<div class="timeline-section">
    <h2>Development Timeline</h2>
    <div class="timeline-container">
        <div class="timeline-row">
            <div>
                <div class="timeline-item education">
                    <span class="item-period">2017.03 - 2023.08</span>
                    <span class="item-title lang-ko">부산대학교 컴퓨터공학부</span>
                    <span class="item-title lang-en">Pusan National University</span>
                    <span class="item-desc lang-ko">정보컴퓨터공학과 공학사 (군복무: 2018.02-2019.12)</span>
                    <span class="item-desc lang-en">B.S. in Computer Science (Military: 2018.02-2019.12)</span>
                </div>
                <div class="timeline-item project">
                    <span class="item-period">2022.02 - 2022.11</span>
                    <span class="item-title lang-ko">Ethereum 경매 플랫폼</span>
                    <span class="item-title lang-en">Ethereum Auction Platform</span>
                    <span class="item-desc lang-ko">Solidity, Web3.js, IPFS 기반 수산물 경매</span>
                    <span class="item-desc lang-en">Seafood auction based on Solidity, Web3.js, IPFS</span>
                </div>
                <div class="timeline-item project">
                    <span class="item-period">2024.01 - 2024.06</span>
                    <span class="item-title">UE5 PVE Game</span>
                    <span class="item-desc lang-ko">게임 엔진 개발 및 Unreal Engine 5 프로젝트</span>
                    <span class="item-desc lang-en">Game engine development and Unreal Engine 5 project</span>
                </div>
            </div>
            <div>
                <div class="timeline-item education">
                    <span class="item-period">2024.06 - 2024.11</span>
                    <span class="item-title">KakaoTech Bootcamp</span>
                    <span class="item-desc lang-ko">LLM-Cloud 기반 웹/앱 서버 및 인프라 개발</span>
                    <span class="item-desc lang-en">LLM-Cloud based web/app server and infrastructure development</span>
                </div>
                <div class="timeline-item work">
                    <span class="item-period">2024.12 - 2025.08</span>
                    <span class="item-title">Rakuten Symphony Korea</span>
                    <span class="item-desc lang-ko">Cloud BU, CNP Storage 개발</span>
                    <span class="item-desc lang-en">Cloud BU, CNP Storage Development</span>
                </div>
                <div class="timeline-item current">
                    <span class="item-period">2025.10 - Present</span>
                    <span class="item-title">Eco2 Project</span>
                    <span class="item-desc lang-ko">2025 새싹톤 우수상(TOP4), Backend/Infra 고도화</span>
                    <span class="item-desc lang-en">2025 SeSACTHON Excellence Award (TOP4), Backend/Infra Enhancement</span>
                </div>
            </div>
        </div>
        <div class="timeline-legend">
            <div class="legend-item"><div class="legend-color education"></div>Education</div>
            <div class="legend-item"><div class="legend-color project"></div>Project</div>
            <div class="legend-item"><div class="legend-color work"></div>Work</div>
            <div class="legend-item"><div class="legend-color current"></div>In Progress</div>
        </div>
    </div>
</div>

<!-- Professional Experience -->
<h2><span class="lang-ko">Professional Experience</span><span class="lang-en">Professional Experience</span></h2>

<div class="experience-item">
    <div class="item-header">
        <div>
            <span class="item-title">Rakuten Symphony Korea</span>
            <span class="item-subtitle"> - Cloud Engineer (Storage Server-side)</span>
        </div>
        <span class="item-period">Dec 2024 - Aug 2025</span>
    </div>
    <p class="item-description lang-ko">Cloud BU | 정규직 | 페타바이트급 프로덕션 분산 스토리지 시스템 개발, 글로벌 팀(인도·일본·한국) 영어 기반 협업</p>
    <p class="item-description lang-en">Cloud BU | Full-time | Petabyte-scale production distributed storage development, global team (India/Japan/Korea) English-based collaboration</p>
    <ul>
        <li><strong>CNP Storage (C/RPC):</strong> <span class="lang-ko">2,000만 유저 통신망 기반 분산 스토리지 — 멀티스레드 동시성 버그 mutex_lock crash 재현·분석, SEGMENT_LOCK down_write→down_read 전환으로 읽기 병렬성 확보 + 프로덕션 데이터 무결성 유지</span><span class="lang-en">Distributed storage for 20M-user telecom networks — Reproduced/analyzed multi-thread concurrency mutex_lock crash, SEGMENT_LOCK down_write→down_read conversion for read parallelism + production data integrity</span></li>
        <li><strong>Object Storage (C):</strong> <span class="lang-ko">Eventual Consistency 모델 기반 분산 게이트웨이 캐시 정합성 패턴 설계, 대용량 오브젝트 고성능 병렬 I/O 처리 구현</span><span class="lang-en">Distributed gateway cache consistency pattern design based on Eventual Consistency model, high-performance parallel I/O for large objects</span></li>
        <li><strong>Tech Sharing & Learning:</strong> <span class="lang-ko">글로벌 팀(인도·일본·한국) 영어 기반 코드 리뷰·아키텍처 설계 논의·장애 분석, 팀 대상 영문 기술 발표를 통한 지속적 학습</span><span class="lang-en">English-based code review, architecture design discussions, and incident analysis across global team (India/Japan/Korea), continuous learning through English technical presentations</span></li>
    </ul>
</div>

<!-- Awards -->
<h2><span class="lang-ko">Awards</span><span class="lang-en">Awards</span></h2>
<ul>
    <li><strong><span class="lang-ko">2025 새싹 해커톤 우수상</span><span class="lang-en">2025 SeSACTHON Excellence Award</span></strong> — <span class="lang-ko">본선 4위/32팀 (예선 181팀) | 주최: 서울특별시, 운영: 데이콘 (Dec 2025)</span><span class="lang-en">Finals 4th/32 teams (Prelims 181 teams) | Host: Seoul Metropolitan Government, Operated by: DACON (Dec 2025)</span></li>
</ul>

<!-- Skills -->
<h2><span class="lang-ko">Skills</span><span class="lang-en">Skills</span></h2>
<table class="skills-table" style="width:100%; border-collapse:collapse; font-size:9pt; margin-bottom:12px;">
    <tr><td style="width:110px; padding:3px 8px 3px 0; font-weight:600; vertical-align:top;">Languages</td><td style="padding:3px 0;">Python, Go, C, Solidity</td></tr>
    <tr><td style="padding:3px 8px 3px 0; font-weight:600; vertical-align:top;">Agent / LLM</td><td style="padding:3px 0;">LangGraph, OpenAI Agents SDK, Gemini SDK, RAG, Prompt Engineering, Token Streaming (SSE), LangSmith</td></tr>
    <tr><td style="padding:3px 8px 3px 0; font-weight:600; vertical-align:top;">Infrastructure</td><td style="padding:3px 0;">Kubernetes, ArgoCD, Istio, OpenTelemetry, KEDA, Docker</td></tr>
    <tr><td style="padding:3px 8px 3px 0; font-weight:600; vertical-align:top;">Messaging</td><td style="padding:3px 0;">RabbitMQ, Redis Streams / Pub/Sub, Taskiq (asyncio), Celery (Gevent)</td></tr>
    <tr><td style="padding:3px 8px 3px 0; font-weight:600; vertical-align:top;">Databases</td><td style="padding:3px 0;">PostgreSQL, Redis, Elasticsearch</td></tr>
    <tr><td style="padding:3px 8px 3px 0; font-weight:600; vertical-align:top;">Architecture</td><td style="padding:3px 0;">Clean Architecture (Port/Adapter), DOMA, Event-Driven, Microservices</td></tr>
    <tr><td style="padding:3px 8px 3px 0; font-weight:600; vertical-align:top;">Observability</td><td style="padding:3px 0;">Prometheus, Grafana, Jaeger, OpenTelemetry, LangSmith</td></tr>
</table>

<!-- Education & Certifications -->
<h2><span class="lang-ko">Education & Certifications</span><span class="lang-en">Education & Certifications</span></h2>

<div class="two-column">
    <div>
        <h3>Education</h3>
        <ul>
            <li><strong><span class="lang-ko">부산대학교</span><span class="lang-en">Pusan National University</span></strong> <span class="lang-ko">정보컴퓨터공학과 공학사 (2017.03 - 2023.08)</span><span class="lang-en">B.S. in Computer Science (2017.03 - 2023.08)</span></li>
            <li><strong><span class="lang-ko">카카오테크 부트캠프</span><span class="lang-en">KakaoTech Bootcamp</span></strong> <span class="lang-ko">백엔드 과정 (2024.06 - 2024.11)</span><span class="lang-en">Backend Course (2024.06 - 2024.11)</span></li>
        </ul>
    </div>
    <div>
        <h3>Certifications</h3>
        <ul>
            <li><strong><span class="lang-ko">정보처리기사</span><span class="lang-en">Engineer Information Processing</span></strong> - HRD Korea (Dec 2024)</li>
            <li><strong>OPIc IH</strong> - ACTFL (Sep 2024)</li>
        </ul>
    </div>
</div>

<!-- Projects -->
<h2><span class="lang-ko">Projects</span><span class="lang-en">Projects</span></h2>

<div class="project-item">
    <div class="item-header">
        <div>
            <span class="item-title">Eco² - LangGraph Multi-Agent AI Service</span>
            <span class="item-subtitle"> | Backend & Infrastructure (Solo)</span>
            <a href="https://mangowhoiscloud.github.io/resume/eco2-portfolio.html" target="_blank" style="font-size: 0.8em; color: #1a73e8; margin-left: 8px;">[Portfolio]</a>
            <a href="https://frontend.dev.growbin.app" target="_blank" style="font-size: 0.8em; color: #1a73e8; margin-left: 4px;">[Service]</a>
        </div>
        <span class="item-period">Oct 2025 - Present</span>
    </div>
    <p class="item-description lang-ko">LLM(GPT-5.2, Gemini-3.0-flash) 기반 Multi-Agent 분리수거 웹앱 백엔드 설계·개발·운영<br>24-Node K8s, 2025 새싹톤 우수상(181팀 중 TOP4)</p>
    <p class="item-description lang-en">LLM(GPT-5.2, Gemini-3.0-flash) Multi-Agent recycling web app backend — design, development, operations<br>24-Node K8s, 2025 SeSACTHON Excellence Award (TOP4/181 teams)</p>

    <div class="metrics">
        <strong>Key Metrics:</strong> VU 50→500 (10x), RPM 60→367.9 (6.1x), Connection Pool 212→33 (84%↓), ext-authz P50 57→7.5ms (87%↓)
    </div>

    <ul>
        <li><strong>LangGraph Multi-Intent Fanout:</strong> <span class="lang-ko">10분류 Intent 분석 후 10종 서브에이전트를 Send API로 동적 병렬 라우팅(waste_rag, location, bulk_waste, weather 등), 복합 질의를 단일 요청에서 병렬 처리</span><span class="lang-en">Dynamic parallel routing of 10 sub-agents via Send API after 10-class Intent analysis (waste_rag, location, bulk_waste, weather, etc.), processing compound queries in a single request</span></li>
        <li><strong>Intent Confidence Scoring:</strong> <span class="lang-ko">다단계 신뢰도 산정(LLM 분류 신뢰도, 키워드 맵 매칭 보정, Chain-of-Intent 문맥 연속성 반영), 저신뢰 시 Fallback Chain(rag → web_search → general_llm) 트리거</span><span class="lang-en">Multi-stage confidence scoring (LLM classification confidence, keyword map matching calibration, Chain-of-Intent context continuity), triggers Fallback Chain (rag → web_search → general_llm) on low confidence</span></li>
        <li><strong>Agent UX (Optimistic Update):</strong> <span class="lang-ko">Optimistic Update(즉시 UI)와 Eventual Consistency(~200ms 지연) 간 타이밍 불일치 해결 — 30초 Retention Window + client_id/server_id 매핑으로 메시지 소실 방지, Message Status State Machine(pending→streaming→committed→failed)</span><span class="lang-en">Resolved timing mismatch between Optimistic Update (immediate UI) and Eventual Consistency (~200ms delay) — 30s Retention Window + client_id/server_id mapping to prevent message loss, Message Status State Machine (pending→streaming→committed→failed)</span></li>
        <li><strong>SSE 재연결 복구:</strong> <span class="lang-ko">클라이언트 재연결 시 Last-Event-ID 헤더 전송 → State KV에서 현재 상태 조회 → XRANGE로 누락 이벤트 catch-up, Token v2 Recoverable Streaming으로 네트워크 끊김 후 토큰 스트림 복구</span><span class="lang-en">Client reconnection sends Last-Event-ID header → Query current state from State KV → XRANGE catch-up for missed events, Token v2 Recoverable Streaming for token stream recovery after network disconnect</span></li>
        <li><strong>Redis Event Bus 3-Tier:</strong> <span class="lang-ko">Streams(영속) + Pub/Sub(실시간 팬아웃) + State KV(복구) 분리, Consumer Group Fan-out으로 SSE(~10ms)와 PostgreSQL 저장(~200ms) 독립 처리</span><span class="lang-en">Streams (persistence) + Pub/Sub (realtime fan-out) + State KV (recovery) separation, Consumer Group Fan-out for independent SSE (~10ms) and PostgreSQL persistence (~200ms) processing</span></li>
        <li><strong>Multi-LLM Resilience:</strong> <span class="lang-ko">LLMClientPort 추상화로 OpenAI/Gemini Provider 런타임 전환, NodePolicy(FAIL_OPEN/CLOSE/FALLBACK) + Circuit Breaker로 노드 장애 시 그래프 중단 방지</span><span class="lang-en">LLMClientPort abstraction for OpenAI/Gemini provider runtime switching, NodePolicy (FAIL_OPEN/CLOSE/FALLBACK) + Circuit Breaker prevents graph interruption on node failure</span></li>
        <li><strong>RAG Pipeline:</strong> <span class="lang-ko">Anthropic Contextual Retrieval 패턴 기반 2-tier RAG(18개 분류 규정 + 80개 상황 태그), Feedback Node가 RAG 품질 평가 후 저품질 시 Web Search Fallback</span><span class="lang-en">2-tier RAG based on Anthropic Contextual Retrieval pattern (18 category regulations + 80 situation tags), Feedback Node evaluates RAG quality and triggers Web Search Fallback on low quality</span></li>
        <li><strong>Auth Offloading:</strong> <span class="lang-ko">Istio ext-authz(Go) Local sync.Map 캐시 + RabbitMQ Fanout broadcast로 Pod 간 블랙리스트 동기화 → 48→1,500 RPS(31×), Cache Hit >99%</span><span class="lang-en">Istio ext-authz(Go) with local sync.Map cache + RabbitMQ Fanout broadcast for cross-pod blacklist sync → 48→1,500 RPS (31×), Cache Hit >99%</span></li>
        <li><strong>Observability:</strong> <span class="lang-ko">Prometheus + Grafana + Jaeger + OpenTelemetry로 분산 트레이싱, LangSmith로 LLM 파이프라인 모니터링</span><span class="lang-en">Distributed tracing with Prometheus + Grafana + Jaeger + OpenTelemetry, LLM pipeline monitoring with LangSmith</span></li>
    </ul>
</div>

<div class="project-item">
    <div class="item-header">
        <div>
            <span class="item-title">Aimo - AI Conflict Mediation Service</span>
            <span class="item-subtitle"> | Backend</span>
            <a href="https://github.com/KTB16Team/Aimo-Backend" target="_blank" style="font-size: 0.8em; color: #1a73e8; margin-left: 8px;">[GitHub]</a>
        </div>
        <span class="item-period">Oct 2024 - Dec 2024</span>
    </div>
    <p class="item-description lang-ko">AI 기반 갈등 중재 서비스 — 3종 AI 모델(GPT-4, BERT, Whisper)로 과실 비율 판정 | KakaoTech Bootcamp Final Project</p>
    <p class="item-description lang-en">AI-powered conflict mediation service — fault ratio judgment with 3 AI models (GPT-4, BERT, Whisper) | KakaoTech Bootcamp Final Project</p>
    <ul>
        <li><strong>AI 비동기 파이프라인:</strong> <span class="lang-ko">음성/이미지를 S3 Presigned URL로 업로드 후 FastAPI AI Server(STT/OCR)에서 처리, Callback API로 판정 결과를 수신하여 과실비율 산출 및 저장</span><span class="lang-en">Upload voice/image via S3 Presigned URL, process in FastAPI AI Server (STT/OCR), receive judgment results via Callback API for fault ratio calculation and storage</span></li>
        <li><strong>API 설계 표준화:</strong> <span class="lang-ko">4인 팀 협업을 위한 공통 응답/예외 처리 체계 수립(BaseResponse, ApiException), Factory Method 패턴으로 계층 간 결합도 감소</span><span class="lang-en">Established common response/exception handling system (BaseResponse, ApiException) for 4-member team collaboration, reduced layer coupling with Factory Method pattern</span></li>
    </ul>
</div>

<div class="project-item">
    <div class="item-header">
        <div>
            <span class="item-title">DREAM - Interactive Story Generation Service</span>
            <span class="item-subtitle"> | Backend & Infrastructure</span>
        </div>
        <span class="item-period">Sep 2024</span>
    </div>
    <p class="item-description lang-ko">LLM & RAG 기반 시니어 꿈 실현 스토리텔링 서비스 | KakaoTech Hackathon</p>
    <p class="item-description lang-en">Senior dream realization storytelling service based on LLM & RAG | KakaoTech Hackathon</p>
    <ul>
        <li><strong>Single-Node Microservices:</strong> <span class="lang-ko">Docker 네트워크로 단일 EC2에서 Spring Backend, FastAPI AI Server, Persistence Layer를 컨테이너 단위 분리</span><span class="lang-en">Container-level separation of Spring Backend, FastAPI AI Server, Persistence Layer on single EC2 via Docker network</span></li>
        <li><strong>LLM + RAG:</strong> <span class="lang-ko">Elasticsearch 벡터 검색 + LangChain RAG로 시니어 꿈 기반 스토리/이미지 생성</span><span class="lang-en">Senior dream-based story/image generation with Elasticsearch vector search + LangChain RAG</span></li>
    </ul>
</div>

<!-- Languages -->
<h2><span class="lang-ko">Languages</span><span class="lang-en">Languages</span></h2>
<ul style="margin-top:4px;">
    <li><strong><span class="lang-ko">한국어</span><span class="lang-en">Korean</span></strong> — Native</li>
    <li><strong><span class="lang-ko">영어</span><span class="lang-en">English</span></strong> — Business Level (OPIc IH)</li>
</ul>

<script>
    function setLang(lang) {
        document.body.className = lang;
        document.getElementById('btn-ko').classList.toggle('active', lang === 'ko');
        document.getElementById('btn-en').classList.toggle('active', lang === 'en');

        if (lang === 'ko') {
            document.title = '류지환 Resume - AI Agent Engineer';
            document.documentElement.lang = 'ko';
        } else {
            document.title = 'Jihwan Ryu Resume - AI Agent Engineer';
            document.documentElement.lang = 'en';
        }

        localStorage.setItem('resume-lang', lang);
    }

    document.addEventListener('DOMContentLoaded', function() {
        const saved = localStorage.getItem('resume-lang');
        if (saved) {
            setLang(saved);
        } else {
            const browserLang = navigator.language || navigator.userLanguage;
            if (browserLang && !browserLang.startsWith('ko')) {
                setLang('en');
            }
        }
    });
</script>

</body>
</html>
